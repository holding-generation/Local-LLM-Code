{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2c31725-2d9c-4ba2-a9fd-1daf8a9d4ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import pipeline, AutoModel\n",
    "import json\n",
    "import textwrap\n",
    "from langchain import HuggingFacePipeline\n",
    "from langchain import PromptTemplate,  LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import pandas as pd\n",
    "import time\n",
    "import gc\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "torch.set_default_device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d476db-c749-4e42-b3bc-6903dab1cd0a",
   "metadata": {},
   "source": [
    "# Setting up LegalBert Large for extractive summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b6b5aec-cdfd-4c61-bc3f-4436cc399c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = \"../legal-bert-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_directory)\n",
    "model = AutoModel.from_pretrained(model_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9c283e6-faa0-414e-a5e8-0bcbde4ecbfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(32000, 1024, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 1024)\n",
       "    (token_type_embeddings): Embedding(2, 1024)\n",
       "    (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-23): 24 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cf9daf0-7410-4222-952f-cc97ef1def87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the majority opinion from the CaseLaw json file\n",
    "def load_and_extract_data(file_path):\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    for o in data[\"casebody\"][\"data\"][\"opinions\"]:\n",
    "        if o[\"type\"] == \"majority\":\n",
    "            return o[\"text\"]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "# Grab chunks of text to summarize\n",
    "# It has an overlap to make sure each chunk has context of the previous chuck\n",
    "def chunk_text_with_overlap(text, chunk_word_count, overlap_word_count):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    index = 0\n",
    "\n",
    "    while index < len(words):\n",
    "        current_chunk_end = index + chunk_word_count\n",
    "        current_chunk_end = min(current_chunk_end, len(words))\n",
    "        chunk = \" \".join(words[index:current_chunk_end])\n",
    "        chunks.append(chunk)\n",
    "\n",
    "        index += chunk_word_count - overlap_word_count\n",
    "\n",
    "        # force it to advance to avoid an infinite loop\n",
    "        if index >= current_chunk_end:\n",
    "            index = current_chunk_end\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# Sort of overkill on saving a summary to a text file\n",
    "# Some naming logic and error checking added in\n",
    "def save_summary_to_text(summary, output_folder, file_path, condensed=False):\n",
    "    \n",
    "    base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    if condensed:\n",
    "        summary_file_name = f\"{base_name}_condensed_summary.txt\"\n",
    "    else:\n",
    "        summary_file_name = f\"{base_name}_summary.txt\"\n",
    "    \n",
    "    summary_file_path = os.path.join(output_folder, summary_file_name)\n",
    "\n",
    "    try:\n",
    "        with open(summary_file_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(summary)\n",
    "        print(f\"Summary successfully written to {summary_file_name}\")\n",
    "    except IOError as e:\n",
    "        print(f\"Unable to write to file: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0949f00-4c1f-4773-a19a-5b4a2799a257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates cosine similarity for sentence embeddings\n",
    "# Pair sentences with scores, then sorts in descending order\n",
    "# Pick top 'num_sentence' number of sentences\n",
    "# START: REFACTOR FROM <https://towardsdatascience.com/extractive-summarization-using-bert-966e912f4142 and https://www.analyticsvidhya.com/blog/2023/03/exploring-the-extractive-method-of-text-summarization/>\n",
    "# Also used GPT-4 in debugging\n",
    "def extractive_summarization(text, num_sentences):\n",
    "\n",
    "    # Use NLTK's sentence tokenizer to split the text into individual sentences\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    tokenized_sentences = [tokenizer.encode(sent, add_special_tokens=True) for sent in sentences]\n",
    "    \n",
    "    max_len = 0\n",
    "    for i in tokenized_sentences:\n",
    "        if len(i) > max_len:\n",
    "            max_len = len(i)\n",
    "    \n",
    "    padded_sentences = []\n",
    "    for i in tokenized_sentences:\n",
    "        while len(i) < max_len:\n",
    "            i.append(0)\n",
    "        padded_sentences.append(i)\n",
    "        \n",
    "    input_ids = torch.tensor(padded_sentences)\n",
    "    \n",
    "    attention_mask = [[float(i != 0.0) for i in seq] for seq in padded_sentences]\n",
    "    attention_mask = torch.tensor(attention_mask)\n",
    "    attention_mask = attention_mask.to(device)\n",
    "    \n",
    "    input_ids = input_ids.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        last_hidden_states = model(input_ids, attention_mask=attention_mask)[0]\n",
    "    \n",
    "    sentence_embeddings = []\n",
    "    for i in range(len(sentences)):\n",
    "        sentence_embeddings.append(torch.mean(last_hidden_states[i], dim=0).cpu().numpy())\n",
    "        \n",
    "    similarity_matrix = cosine_similarity(sentence_embeddings)\n",
    "    \n",
    "    sentence_scores = [sum(similarity_matrix[i]) for i in range(len(sentences))]\n",
    "    \n",
    "    sentence_score_pairs = list(enumerate(sentence_scores))\n",
    "    \n",
    "    sorted_sentences = sorted(sentence_score_pairs, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    summary_sentences = [sentences[index] for index, _ in sorted_sentences[:num_sentences]]\n",
    "    \n",
    "    summary = ' '.join(summary_sentences)\n",
    "    \n",
    "    return summary\n",
    "# END: REFACTOR FROM <https://towardsdatascience.com/extractive-summarization-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b82d019b-bf3a-450a-9d74-5061d64aa726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarizing a case document and using a csv file to keep track of\n",
    "# This code has been refactored seeveral times so the name and batch_size are kind of outdated\n",
    "def summarize_a_batch_of_case_documents(batch_size, processed_files_csv):\n",
    "    start = time.time()\n",
    "    if os.path.exists(processed_files_csv):\n",
    "        processed_files_df = pd.read_csv(processed_files_csv)\n",
    "    else:\n",
    "        processed_files_df = pd.DataFrame(columns=[\"file_name\", \"time_elapsed\"])\n",
    "    processed_count = 0\n",
    "    filenames = sorted(os.listdir(input_folder))\n",
    "    \n",
    "    # Start from where the last entry left off\n",
    "    last_processed_index = 0\n",
    "    if not processed_files_df.empty:\n",
    "        last_filename = processed_files_df['file_name'].iloc[-1]\n",
    "        last_processed_index = filenames.index(last_filename) + 1\n",
    "\n",
    "    # Process files starting from the last processed one\n",
    "    for filename in filenames[last_processed_index:]:\n",
    "        if processed_count >= batch_size:\n",
    "            break\n",
    "        print(\"Processing: \", filename)\n",
    "        if filename.endswith(\".json\"):\n",
    "            if filename in processed_files_df['file_name'].values:\n",
    "                    print(f\"File {filename} has already been processed. Skipping.\")\n",
    "                    continue\n",
    "            else:\n",
    "                try:\n",
    "                    summarize_a_case_document(filename)\n",
    "                except:\n",
    "                    print(f\"Error processing {filename}\")\n",
    "                processed_count += 1\n",
    "                end = time.time()\n",
    "                new_row = {\"file_name\": filename,\n",
    "                           \"time_elapsed\": end - start\n",
    "                          }\n",
    "                processed_files_df = pd.concat([processed_files_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "                processed_files_df.to_csv(processed_files_csv, index=False)\n",
    "\n",
    "# This code summarizes a case when given a json file\n",
    "# It gets the major opinion, chucks it, summarizes it, then save it as an individual txt file\n",
    "def summarize_a_case_document(filename):\n",
    "    file_path = os.path.join(input_folder, filename)\n",
    "    opinion = load_and_extract_data(file_path)\n",
    "    opinion = str(opinion)\n",
    "    \n",
    "    chunk_word_count = 1000\n",
    "    overlap_word_count = 200\n",
    "    \n",
    "    chunks = chunk_text_with_overlap(opinion, chunk_word_count, overlap_word_count)\n",
    "\n",
    "    chunk_summaries = summarize_chunks(chunks, chunk_word_count)\n",
    "    final_summary = ' '.join(chunk_summaries)\n",
    "    \n",
    "    save_summary_to_text(final_summary, output_folder, file_path, condensed=False)\n",
    "\n",
    "# It's here that we decided the number of sentences to use in extractive summarization\n",
    "# we picked between 2 and 7 sentences\n",
    "# given that chunk in roughly 1000 words, we would add a sentence every 100 words\n",
    "def summarize_chunks(chunks, chunk_word_count):\n",
    "    min_sentences = 2\n",
    "    standard_summary_length = 10\n",
    "    max_sentences = 7\n",
    "\n",
    "    summaries = []\n",
    "\n",
    "    for chunk in chunks:\n",
    "        chunk_length = len(chunk.split())\n",
    "        proportional_sentences_number = int((chunk_length / chunk_word_count) * standard_summary_length)\n",
    "        \n",
    "        sentences_to_summarize = max(proportional_sentences_number, min_sentences)\n",
    "\n",
    "        sentences_to_summarize = min(max_sentences, proportional_sentences_number)\n",
    "        \n",
    "        # Perform extractive summarization on the chunk using 'sentences_to_summarize' as the number of sentences to include in the summary\n",
    "        summary = extractive_summarization(chunk, sentences_to_summarize)\n",
    "        summaries.append(summary)\n",
    "        \n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1dbf8d-90ff-4934-a088-3c9c706a044a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "598a8920-06d9-4e1c-9ab0-89d4c6f2cd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo_folder = 'Local-LLM-Code'\n",
    "input_folder = 'input_files_from_CaseLaw'\n",
    "output_folder = 'output_summaries_from_LegalBert_large'\n",
    "# output_folder = os.path.join(demo_folder, output_folder_name)\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "processed_files_df = None\n",
    "processed_files_csv = 'processed_files_for_demo.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcd1dad9-074e-4a54-8357-8bf92650a68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(os.listdir(input_folder))):\n",
    "    summarize_a_batch_of_case_documents(1, processed_files_csv)\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a4d5f56-6fa8-476d-ac46-3ff31899514b",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_bert_summaries = []\n",
    "for filename in os.listdir(output_folder):\n",
    "    file_path = os.path.join(output_folder, filename)\n",
    "    file = open(file_path, \"r\")\n",
    "    bert_summary = file.read()\n",
    "    list_of_bert_summaries.append(bert_summary)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3607fc1-e621-4b54-bca4-d5e0db792534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lastly, the joinder of William as a respondent will also serve the child’s interest in having her paternity decided swiftly and finally, for a decision rendered in a proceeding in which he is not a party cannot bind him, and leaves open the possibility of a later order declaring him to be the father (see, Matter of Tyrone G. v Fifi N., supra, at 14; cf., Matter of Cathleen P. v Gary P., 63 NY2d 805, 808, supra). [Sandra C.] v Thomas J.S., 100 AD2d 119, 122-123; 1 Schatkin, Disputed Paternity Proceedings § 8.08 [4th rev ed]), has made it more realistic to view a paternity proceeding as a means of actually and conclusively determining the identity of a child’s biological father (see, Matter of Commissioner of Social Servs. Moreover, with the joinder of William as an \"alleged father”, the court can order him to submit to a blood test (see, Family Ct Act § 532 [a]; CPLR 3121 [a]), the results of which, if they exclude him as the child’s father, will provide the clear and convincing evidence petitioner needs to rebut the presumption of legitimacy (see, e.g., Ghaznavi v Gordon, 163 AD2d 194, 195). Accordingly, where, as here, a mother’s husband has been a substantial presence in the child’s life and desires to continue to exercise parental rights, the need for joining him, as a party whose interests \"might be inequitably aifected by” the resulting order of filiation (CPLR 1001 [a]), is manifest and may be ordered by the court on its own motion (cf., Matter of Tyrone G. v Fifi N., 189 AD2d 8, 15-16; Albert C. v Joan C., 110 AD2d 803, 804). And if William refuses to submit to the test, an adverse inference may then be drawn against him (see, Fitzgerald v Tamola, 199 AD2d 122, 123; Matter of Joseph P.M. v Boyce R., 127 Misc 2d 931, 933-934). Family Court, following a hearing, found respondent’s admission that she had engaged in sexual relations with petitioner at the relevant time, coupled with results of a human leucocyte antigen test showing a 99.53% probability that petitioner is the child’s father, sufficient to overcome the presumption of legitimacy that arises when a child is born to a married woman (see, Matter of Lane v Eno, 277 App Div 324, 325), and entered an order of filiation declaring petitioner to be the child’s father. v Duane HH., 95 AD2d 466, 467-468, affd 63 NY2d 859), the consequences of a proceeding of this type—both for the child and for the involved adults— are now considerably greater than they have been in the past (see, Matter of Cathleen P. v Gary P., 63 NY2d 805, 807; Matter of Kordek v Wood, 90 AD2d 209, 213). Matter of Tyrone G. v Fifi N., supra, at 14; cf., Matter of Cathleen P. v Gary P., 63 NY2d 805, 808, supra).\n"
     ]
    }
   ],
   "source": [
    "print(list_of_bert_summaries[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1fdb098-3dcf-45aa-8373-97dda0012bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French Lilly further testified that some time thereafter the policy written by Mrs. Foster was mailed to him, inasmuch as plaintiff also resided in Wyoming County, and that he thereupon mailed the policy to the plaintiff, not at that time being aware of the fact that the policy was written for the same man who had been refused insurance previously by the witness. As a result of the telephone conversation, the plaintiff called upon Mrs. Foster, who issued the insurance policy in question. Later, however, the home office learned of the false answer contained in the application; and on March 8, 1957, wrote a letter to the plaintiff detailing the facts in relation to the false answer contained in the application, and notifying the plaintiff that his insurance policy was rescinded. At the time the letter of December 20 was written, the home office did not know of the accident involving the cow, or of the occurrence which resulted in the destruction of the automobile, and did not know of the fact that the application made by plaintiff contained a false statement of facts. French Lilly of Oceana, in Wyoming County, an agent for the defendant company, testified that “in the neighborhood of July in 1956”, the plaintiff showed to the witness a letter disclosing that the plaintiff’s automobile insurance with another company was being cancelled and that thereupon the witness refused to write a policy of insurance on behalf of the defendant company covering plaintiff’s automobile. As a consequence thereof, the home office wrote a letter to the plaintiff, dated December 20, 1956, three days after the automobile was demolished, notifying the plaintiff that his insurance policy would be cancelled as of January 2, 1957, and advising him to obtain proper insurance in the meantime with another company. The defendant offered the letter of March 8 for introduction in evidence, the plaintiff objected, and the court refused to permit the introduction of such letter as a part of the evidence to be considered by the jury. The defendant offered the letter of March 8 for introduction in evidence, the plaintiff objected, and the court refused to permit the introduction of such letter as a part of the evidence to be considered by the jury. Thereupon, the court made the following statement to the jury: “Ladies and gentlemen of the jury, there are two questions to be decided in this case. After the completion of the testimony at the trial before a jury, the defendant made a motion for a directed verdict in its favor, which motion was overruled. In his written opinion, which was made a part of the record, the eminent trial judge stated: “I am of the opinion that the knowledge of the agent of the company at Oceana is imputed to its principal, the defendant company, and the defendant company having had knowledge of a prior cancellation through its agent and in its principal offices, had an election to either treat the policy as void or rescind it as of a future date. The company elected to rescind and prior to the date of rescinding, the loss occurred.” Prior to the time of the trial, the defendant filed its specification of defense in accordance with the provisions of Code, 56-4-21, a portion of which was as follows: “That the plaintiff fraudulently procured the said policy of insurance by the wilful, intentional, making of false and fraudulent answers and misrepresentations upon his application for said policy of insurance, with full knowledge at the time of making said false statements and answers that the defendant would not have issued said policy of insurance had the defendant known that the statements and answers as given were false. The trial court deducted this sum from $2,800.00, the value placed on the automobile by the jury’s verdict, and entered judgment for the plaintiff for the balance, amounting to $271.45. The defendant, however, in order to save the point, took testimony in relation to the letter outside the presence and hearing of the jury, and the letter was made a part of the record. 2 syl., 140 S. E. 61; Kincaid v. Equitable Life Assur. 45 C.J.S., Insurance, Section 605, page 438. SchWarzbach v. Ohio Valley Protective Union, 25 W. Va. 622, syl. “The insurer is not precluded from setting up the falsity of answers in the application where it appears that insured knew at the time they were being written or before signing the application that they were written falsely in order to defraud the company.” 45 C.J.S., Insurance, Section 732, page 741. It has been held that, under such a state of facts, “the policy is thereby forfeited.” Saltesz v. The Sovereign Camp of the Woodmen of the World, 110 W. Va. 513, syl., 159 S. E. 513. “Plaintiff cannot, at the trial or in the appellate court, rely on an estoppel not set forth in his reply.” Capehart v. Mutual Benefit Health and Accident Ass’n., 111 W. Va. 317, syl., 161 S. E. 609. Health & Accident v. Ratcliffe, 163 Va. 325, 175 S. E. 870, 874. It has been held that, under such circumstances, “the policy will ordinarily be forfeited.” Faulkiner v. Equitable Life Insurance Co., 144, W. Va. 193, syl., 107 S. E. 2d 360. It has been held that, under such a state of facts, “the policy is thereby forfeited.” Saltesz v. The Sovereign Camp of the Woodmen of the World, 110 W. Va. 513, syl., 159 S. E. 513. Although in some jurisdictions it is held that a contract of insurance procured by fraud is void, as a general rule, such a contract is voidable at the option of insurer on discovery of the fraud.” 45 C.J.S., Insurance, Section 473(2), page 152.\n"
     ]
    }
   ],
   "source": [
    "print(list_of_bert_summaries[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29795b1b-49db-4ddf-92ce-45abf0f53c1c",
   "metadata": {},
   "source": [
    "# Full Sentence Holding Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ae2777c-a5ac-44f9-8849-967b34d8002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_model_directory = \"../Llama-2-7b-chat-hf\"\n",
    "llama_tokenizer = AutoTokenizer.from_pretrained(llama_model_directory)\n",
    "\n",
    "llama_model = AutoModelForCausalLM.from_pretrained(llama_model_directory,\n",
    "                                                     device_map='auto',\n",
    "                                                     torch_dtype=torch.float16,\n",
    "                                                     load_in_4bit=True\n",
    "                                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12925c7b-0ad3-4d88-bebd-bb7be6b987e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_pipe = pipeline(\"text-generation\",\n",
    "                model=llama_model,\n",
    "                tokenizer=llama_tokenizer,\n",
    "                torch_dtype=torch.bfloat16,\n",
    "                device_map=\"auto\",\n",
    "                max_new_tokens = 1024,\n",
    "                do_sample=True,\n",
    "                top_k=30,\n",
    "                num_return_sequences=1,\n",
    "                eos_token_id=tokenizer.eos_token_id\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "850e7d3f-bb39-4471-a414-c1e497f75384",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
    "B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
    "DEFAULT_SYSTEM_PROMPT = \"You are a legal expert who specializes in extracting accurate and concise holdings from case documents.\"\n",
    "\n",
    "def get_prompt(instruction, new_system_prompt=DEFAULT_SYSTEM_PROMPT ):\n",
    "    SYSTEM_PROMPT = B_SYS + new_system_prompt + E_SYS\n",
    "    prompt_template =  B_INST + SYSTEM_PROMPT + instruction + E_INST\n",
    "    return prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d59d33c-70fc-42b9-a38c-be33a20adf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"Use the case document to extract the concise holding. {text}\"\n",
    "system_prompt = \"You are a legal expert who specializes in extracting accurate and concise holdings from case documents.\"\n",
    "\n",
    "llama_llm = HuggingFacePipeline(pipeline = llama_pipe, model_kwargs = {'temperature':0})\n",
    "\n",
    "llama_template = get_prompt(instruction, system_prompt)\n",
    "\n",
    "llama_prompt = PromptTemplate(template=llama_template, input_variables=[\"text\"])\n",
    "\n",
    "llama_llm_chain = LLMChain(prompt=llama_prompt, llm=llama_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87bfb505-0c12-410e-9f34-795e21c8064a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_holdings = []\n",
    "summaries_folder = 'output_summaries_from_LegalBert_large'\n",
    "for summary in list_of_bert_summaries:\n",
    "    holding = llama_llm_chain.run(summary)\n",
    "    list_of_holdings.append(holding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "911bcc4b-69a9-4951-8a7b-51d38596e445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  The holding in this case is that the court may order the joinder of a man who is alleged to be the biological father of a child, even if he is not a party to the proceeding, in order to determine the child's paternity. The court may order the man to submit to a blood test to determine his paternity, and if he refuses, an adverse inference may be drawn against him. The court found that the results of a human leucocyte antigen test showing a 99.53% probability that the petitioner is the child's father were sufficient to overcome the presumption of legitimacy that arises when a child is born to a married woman.\n"
     ]
    }
   ],
   "source": [
    "print(list_of_holdings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "057a16d4-5108-468d-b2a3-b8b90535ba15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  The holding of the case is that the defendant company had the right to rescind the insurance policy issued to the plaintiff due to the plaintiff's fraudulent misrepresentations in the application. The court held that the defendant company had knowledge of the fraudulent answers and misrepresentations through its agent in Oceana, and therefore had an election to either treat the policy as void or rescind it as of a future date. Since the defendant company elected to rescind the policy, the loss occurred prior to the date of rescinding, and the defendant was entitled to deduct the value of the automobile from the amount of the plaintiff's recovery. The court also held that the plaintiff could not rely on an estoppel not set forth in his reply, and that the policy was thereby forfeited under the circumstances of the case.\n"
     ]
    }
   ],
   "source": [
    "print(list_of_holdings[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b886a73-d494-4c77-8b9d-ae073b1c5bb7",
   "metadata": {},
   "source": [
    "# Parenthetical Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee7bbcf3-2b75-491c-9a45-927b160c2c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"Use the case document to extract the concise holding and phrase it as a parenthetical, which should look something like this: holding that the balance between costs and benefits comes out against applying the exclusionary rule in civil deportation hearings. {text}\"\n",
    "system_prompt = \"You are a legal expert who specializes in extracting accurate and concise parenthetical holdings from case documents. Give only the holdings, no other breakdowns or extra text.\"\n",
    "\n",
    "llama_llm = HuggingFacePipeline(pipeline = llama_pipe, model_kwargs = {'temperature':0})\n",
    "\n",
    "llama_template = get_prompt(instruction, system_prompt)\n",
    "\n",
    "llama_prompt = PromptTemplate(template=llama_template, input_variables=[\"text\"])\n",
    "\n",
    "llama_llm_chain = LLMChain(prompt=llama_prompt, llm=llama_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e792f452-64e1-4a07-b057-f8c456a5f84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_parentheticals = []\n",
    "summaries_folder = 'output_summaries_from_LegalBert_large'\n",
    "for summary in list_of_bert_summaries:\n",
    "    parenthetical = llama_llm_chain.run(summary)\n",
    "    list_of_parentheticals.append(parenthetical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5e0424d-cc12-400f-bf7d-e08071488f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Here are the concise holdings from the case document:\n",
      "\n",
      "1. The balance between costs and benefits comes out against applying the exclusionary rule in civil deportation hearings.\n",
      "2. Joinder of William as a respondent will serve the child’s interest in having her paternity decided swiftly and finally, and leaves open the possibility of a later order declaring him to be the father.\n",
      "3. Where a mother’s husband has been a substantial presence in the child’s life and desires to continue to exercise parental rights, the need for joining him as a party whose interests might be inequitably affected by the resulting order of filiation is manifest, and may be ordered by the court on its own motion.\n",
      "4. If William refuses to submit to a blood test, an adverse inference may be drawn against him.\n"
     ]
    }
   ],
   "source": [
    "print(list_of_parentheticals[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0fd796d-b606-4581-baab-8082bf8b5001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Holding: The court held that the policy was forfeited due to the plaintiff's fraudulent misrepresentations on the application.\n"
     ]
    }
   ],
   "source": [
    "print(list_of_parentheticals[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370dd645-d87f-4b28-b680-d4ed3b85737d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
