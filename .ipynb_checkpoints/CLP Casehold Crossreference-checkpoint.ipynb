{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45844b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "file_path = 'train.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(file_path, encoding='utf-8')\n",
    "except UnicodeDecodeError:\n",
    "    df = pd.read_csv(file_path, encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6a9b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.head(5).iterrows():\n",
    "        print(f\"Data point {index + 1}:\")\n",
    "\n",
    "        for col_name in df.columns:\n",
    "            print(f\"{col_name}: {row[col_name]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31da7d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Going through the train.csv from CaseHold on hugging face\n",
    "# This was for going through the case excert and the correct multiple choice holding\n",
    "# Iterate through the first 5 rows\n",
    "for index, row in df.head(5).iterrows():\n",
    "    print(f\"Data point {index + 1}:\")\n",
    "\n",
    "    col_0_data = row.iloc[1]\n",
    "    col_11_data = row.iloc[12]\n",
    "\n",
    "    # Print the data from columns 0 and 11\n",
    "    print(f\"Column 0: {col_0_data}\")\n",
    "    print(f\"Column 11: {col_11_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbb6972",
   "metadata": {},
   "source": [
    "# Code to get reference case documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e8eedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "import math\n",
    "import gc\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee895c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_case_citations(text, num_of_words=18):\n",
    "\n",
    "    # First, we attempt to extract 'num_of_words' before \"(<HOLDING>)\"\n",
    "    match = re.search(fr'((?:\\S+\\s+){{0,{num_of_words}}})\\(<HOLDING>\\)', text)\n",
    "    # default to full text if no specific match\n",
    "    extracted_text = text  \n",
    "\n",
    "    if match:\n",
    "        # If a match is found, extract the specific portion of the text\n",
    "        extracted_text = ' '.join(match.group(1).split()[-num_of_words:])\n",
    "        \n",
    "    # START: Copied from GPT-4\n",
    "    citation_pattern = r'(\\d+)\\s([A-Za-z0-9.]+)\\s(\\d+)'\n",
    "    # END: Copied from GPT-4\n",
    "    \n",
    "    matches = re.findall(citation_pattern, extracted_text)\n",
    "\n",
    "    # Build list of case citations from matches\n",
    "    case_citations = [' '.join(match) for match in matches]\n",
    "\n",
    "    if not case_citations:\n",
    "        print(\"No case citations found in the provided text.\")\n",
    "\n",
    "    return case_citations, extracted_text  \n",
    "\n",
    "def search_cases(citations):\n",
    "    if not citations:\n",
    "        print(\"No citations provided.\")\n",
    "        return None\n",
    "\n",
    "    # Use the first citation in the list\n",
    "    first_citation = citations[0]\n",
    "\n",
    "    # Define the endpoint\n",
    "    url = 'https://api.case.law/v1/cases/'\n",
    "    headers = {'Authorization': f'Token {CASELAW_TOKEN}'}\n",
    "    params = {\n",
    "        'cite': first_citation,\n",
    "        'full_case': 'true'\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        case_data = response.json()\n",
    "        cases_results = case_data.get('results', [])\n",
    "\n",
    "        if cases_results:\n",
    "            # Taking the first case even if multiple cases match the citation\n",
    "            return cases_results[0]\n",
    "        else:\n",
    "            print(f\"No cases found for citation {first_citation}.\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f'Failed to retrieve cases for citation {first_citation}: {response.status_code}')\n",
    "        return None\n",
    "\n",
    "def save_case(case, row_number, subdir='ref_case_jsons'):\n",
    "    case_id = case['id']\n",
    "    state = case['jurisdiction']['name_long']\n",
    "\n",
    "    # Save case to a JSON file\n",
    "    if not os.path.exists(subdir):\n",
    "        os.makedirs(subdir)\n",
    "    \n",
    "    with open(os.path.join(subdir, f'case_{row_number + 1}.json'), 'w') as json_file:\n",
    "        json.dump(case, json_file, indent=4)\n",
    "\n",
    "    return case_id, state\n",
    "\n",
    "def process_dataframe(df, start_row=0, num_rows_to_process=5, status_file='case_references.csv', subdir='ref_case_jsons'):\n",
    "    if os.path.exists(status_file):\n",
    "        queries_df = pd.read_csv(status_file)\n",
    "        # Ensuring we are not re-processing already processed rows\n",
    "        start_row = max(queries_df['row_number'].max() + 1, start_row)\n",
    "    else:\n",
    "        queries_df = pd.DataFrame(columns=['row_number', \n",
    "                                           'query_status', \n",
    "                                           'case_id', \n",
    "                                           'state', 'error', \n",
    "                                           'correct_choice_index', \n",
    "                                           'correct_answer_value', \n",
    "                                           'extracted_text'])\n",
    "\n",
    "    for row_number in range(start_row, start_row + num_rows_to_process):\n",
    "        if row_number >= len(df):\n",
    "            print(\"Reached the end of the dataframe.\")\n",
    "            break\n",
    "\n",
    "        correct_choice_index = df.iloc[row_number].iloc[12]\n",
    "\n",
    "        # Check if the multiple choice values in CaseHold are valid (0-4) since a few were not valid\n",
    "        if pd.isna(correct_choice_index) or correct_choice_index not in range(5):\n",
    "            print(f\"Skipping row {row_number} due to invalid or missing correct choice index.\")\n",
    "            continue\n",
    "\n",
    "        # The correct multiple answer (0-4) was actually just 2 columns away\n",
    "        correct_answer_value = df.iloc[row_number].iloc[int(correct_choice_index) + 2]\n",
    "\n",
    "        text_content = df.iloc[row_number].iloc[1]\n",
    "        citations, extracted_text = extract_case_citations(text_content) \n",
    "        case = search_cases(citations)\n",
    "\n",
    "        query_status = None\n",
    "        case_id = None\n",
    "        state = None\n",
    "        error = False\n",
    "\n",
    "        if case:\n",
    "            casebody_status = case.get('casebody', {}).get('status')\n",
    "            if casebody_status == 'ok':\n",
    "                try:\n",
    "                    case_id, state = save_case(case, row_number, subdir=subdir)\n",
    "                    query_status = 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Error saving case for row {row_number}: {e}\")\n",
    "                    error = True\n",
    "                    query_status = 0\n",
    "            else:\n",
    "                print(f\"Casebody status is not 'ok' for row {row_number}. Exiting loop.\")\n",
    "                break\n",
    "        else:\n",
    "            query_status = 0  # failure or no results\n",
    "\n",
    "        # Updateing the status dataframe\n",
    "        new_row = {\n",
    "            'row_number': row_number, \n",
    "            'query_status': query_status, \n",
    "            'case_id': case_id, \n",
    "            'state': state, \n",
    "            'error': error,\n",
    "            'correct_choice_index': correct_choice_index,\n",
    "            'correct_answer_value': correct_answer_value,\n",
    "            'extracted_text': extracted_text\n",
    "        }\n",
    "        queries_df = pd.concat([queries_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "        print(str(row_number)+\":\",str(new_row['case_id']))\n",
    "        \n",
    "        # Save after each row to preserve data in case of interruption\n",
    "        # Attempting exponential backoff when saveing to csv\n",
    "        max_attempts = 5  # Maximum number of retry attempts\n",
    "        backoff_factor = 2  # Factor by which the wait time increases each attempt\n",
    "\n",
    "        try:\n",
    "            queries_df.to_csv(status_file, index=False)\n",
    "        except Exception as e:\n",
    "            print(\"Initial attempt failed, entering backoff loop.\")\n",
    "            for attempt in range(1, max_attempts):\n",
    "                try:\n",
    "                    # Backoff before retrying\n",
    "                    time.sleep(backoff_factor ** attempt)  \n",
    "                    queries_df.to_csv(status_file, index=False)\n",
    "                    print(f\"File saved successfully on attempt {attempt + 1}.\")\n",
    "                    break \n",
    "                except Exception as e:\n",
    "                    print(f\"Attempt {attempt + 1} failed, retrying...\")\n",
    "            else:\n",
    "                print(\"Failed to save the file after several attempts.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1084ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_case_citations(df.iloc[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd4a3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[14,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a02d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bd049d-4b53-4565-9459-d490e59776e9",
   "metadata": {},
   "source": [
    "## -getting the cases for train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeceb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "CASELAW_TOKEN = os.getenv('CASELAW_TOKEN')\n",
    "process_dataframe(df, num_rows_to_process=1,subdir='ref_case_jsons')\n",
    "\n",
    "# for i in range(25):\n",
    "#     process_dataframe(df, num_rows_to_process=500,subdir='ref_case_jsons')\n",
    "#     gc.collect()\n",
    "#     time.sleep(5)\n",
    "\n",
    "file_path = 'train.csv'\n",
    "try:\n",
    "    df = pd.read_csv(file_path, encoding='utf-8')\n",
    "except UnicodeDecodeError:\n",
    "    df = pd.read_csv(file_path, encoding='iso-8859-1')\n",
    "    \n",
    "for i in range(12):\n",
    "    process_dataframe(df, num_rows_to_process=500,status_file='case_references_train.csv',subdir='ref_case_jsons_train')\n",
    "    gc.collect()\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ab140b",
   "metadata": {},
   "source": [
    "### - getting the cases from val.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991d7602-c36f-48e2-b873-72a1c029de5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'val.csv'\n",
    "try:\n",
    "    df = pd.read_csv(file_path, encoding='utf-8')\n",
    "except UnicodeDecodeError:\n",
    "    df = pd.read_csv(file_path, encoding='iso-8859-1')\n",
    "    \n",
    "for i in range(12):\n",
    "    process_dataframe(df, num_rows_to_process=500,status_file='case_references_val.csv',subdir='ref_case_jsons_val')\n",
    "    gc.collect()\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89dc341",
   "metadata": {},
   "source": [
    "### - getting the cases from test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb41598c-3f52-4c36-8f4b-ab0d615a0248",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'test.csv'\n",
    "try:\n",
    "    df = pd.read_csv(file_path, encoding='utf-8')\n",
    "except UnicodeDecodeError:\n",
    "    df = pd.read_csv(file_path, encoding='iso-8859-1')\n",
    "    \n",
    "for i in range(12):\n",
    "    process_dataframe(df, num_rows_to_process=500,status_file='case_references_test.csv',subdir='ref_case_jsons_test')\n",
    "    gc.collect()\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d635dcb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
